{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width:100%; height:60px; background-color:aqua; display:flex\">\n",
    "<div style=\"display:flex; flex-direction:row; justify-content:center\">\n",
    "<h2 style=\"color:white\"><strong>Decision Tree</strong></h2>\n",
    "</div>\n",
    "</div>\n",
    "<h3 style=\"color:white\">A decision tree is a flowchart-like tree structure where an internal node represents a feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome.</h3>\n",
    "<h3 style=\"color:white\">The time complexity of decision trees is a function of the number of records and attributes in the given data. The decision tree is a distribution-free or non-parametric method which does not depend upon probability distribution assumptions. Decision trees can handle high-dimensional data with good accuracy.</h3>\n",
    "<div style=\"width:100%; height:auto; display:flex; flex-direction:row; justify-content:space-around;\">\n",
    "<img style=\"width:45%;height:auto\" src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/Decision-Tree-Classifier-Support.png\">\n",
    "<img style=\"width:45%;height:auto\" src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/decision_tree_heart_attack.png\">\n",
    "</div>\n",
    "<h2 style=\"color:white\">How Does the Decision Tree Algorithm Work?</h2>\n",
    "<h3 style=\"color:grey; font-style:italic\">The basic idea behind any decision tree algorithm is as follows:\n",
    "<ol style=\"color:aqua; font-style:italic\">\n",
    "<li>\n",
    "Select the best attribute using Attribute Selection Measures (ASM) to split the records.\n",
    "</li>\n",
    "<li>\n",
    "Make that attribute a decision node and breaks the dataset into smaller subsets.\n",
    "</li>\n",
    "<li>\n",
    "Start tree building by repeating this process recursively for each child until one of the conditions will match:\n",
    "<ul>\n",
    "<li>\n",
    "All the tuples belong to the same attribute value.\n",
    "</li>\n",
    "<li>\n",
    "There are no more remaining attributes.\n",
    "</li>\n",
    "<li>\n",
    "There are no more instances.\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ol>\n",
    "</h3>\n",
    "<img src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/decision_tree_generation.webp\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 12:18:10.607760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-23 12:18:10.877243: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-23 12:18:10.951173: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-23 12:18:14.548141: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import tensorflow as ts, keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('salaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16 entries, 0 to 15\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   company                16 non-null     object\n",
      " 1   job                    16 non-null     object\n",
      " 2   degree                 16 non-null     object\n",
      " 3   salary_more_then_100k  16 non-null     int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 640.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job</th>\n",
       "      <th>degree</th>\n",
       "      <th>salary_more_then_100k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google</td>\n",
       "      <td>sales executive</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>google</td>\n",
       "      <td>sales executive</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google</td>\n",
       "      <td>business manager</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google</td>\n",
       "      <td>business manager</td>\n",
       "      <td>masters</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google</td>\n",
       "      <td>computer programmer</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>google</td>\n",
       "      <td>computer programmer</td>\n",
       "      <td>masters</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abc pharma</td>\n",
       "      <td>sales executive</td>\n",
       "      <td>masters</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abc pharma</td>\n",
       "      <td>computer programmer</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abc pharma</td>\n",
       "      <td>business manager</td>\n",
       "      <td>bachelors</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abc pharma</td>\n",
       "      <td>business manager</td>\n",
       "      <td>masters</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company                  job     degree  salary_more_then_100k\n",
       "0      google      sales executive  bachelors                      0\n",
       "1      google      sales executive    masters                      0\n",
       "2      google     business manager  bachelors                      1\n",
       "3      google     business manager    masters                      1\n",
       "4      google  computer programmer  bachelors                      0\n",
       "5      google  computer programmer    masters                      1\n",
       "6  abc pharma      sales executive    masters                      0\n",
       "7  abc pharma  computer programmer  bachelors                      0\n",
       "8  abc pharma     business manager  bachelors                      0\n",
       "9  abc pharma     business manager    masters                      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:aqua; font-weight:bold\">What is Gini Impurity?</h2>\n",
    "<h3 style=\"color:white\">Gini Impurity is a measurement used to build Decision Trees to determine how the features of a dataset should split nodes to form the tree. More precisely, the Gini Impurity of a dataset is a number between 0-0.5, which indicates the likelihood of new, random data being misclassified if it were given a random class label according to the class distribution in the dataset.</h3>\n",
    "<div style=\"width:100%; height:auto; display:flex; flex-direction:row; justify-content:space-around;\">\n",
    "<img style=\"width:45%;height:auto\" src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/gini-impurity-diagram.width-1200.png\">\n",
    "<img style=\"width:45%;height:auto\" src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/gini_vs_entropy.jfif\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:aqua; font-weight:bold\">What is Entropy?</h2>\n",
    "<h3 style=\"color:white\">Entropy is an information theory metric that measures the impurity or uncertainty in a group of observations. It determines how a decision tree chooses to split data. The image below gives a better description of the purity of a set.</h3>\n",
    "<div style=\"width:100%; height:auto; display:flex; flex-direction:row; justify-content:space-around;\">\n",
    "<img style=\"width:45%;height:auto\" src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/entropy_formula_working.png\">\n",
    "<img style=\"width:40%;height:auto\" src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/purity_entropy.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:aqua; font-weight:bold\">What is Information Gain?</h2>\n",
    "<h3 style=\"color:white\">Claude Shannon invented the concept of entropy, which measures the impurity of the input set. In physics and mathematics, entropy is referred to as the randomness or the impurity in a system. In information theory, it refers to the impurity in a group of examples. <strong>Information gain</strong> is the decrease in entropy. Information gain computes the difference between entropy before the split and average entropy after the split of the dataset based on given attribute values. ID3 (Iterative Dichotomiser) decision tree algorithm uses information gain.</h3>\n",
    "<div style=\"width:100%; height:auto; display:flex; flex-direction:row; justify-content:space-around;\">\n",
    "<img style=\"width:32%;height:auto\" src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/information_gain.png\">\n",
    "<img style=\"width:32%;height:auto\" src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/information_gain_two.png\">\n",
    "<img style=\"width:32%;height:auto\" src=\"/home/ahmedunix/data_Science_Work/Machine_Learning/10_Decision_Tree/information_gain_vs_entropy.png\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-work-mqn9WFvk-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
